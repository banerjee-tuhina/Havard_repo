{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram Scrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm scrapes posts and messages from instagram. For scraping posts the code uses 2 hashtags, #itstestingimage_3 and #itstestingnews_2 to scrape images and news respectively. The messages are scraped using xpath. Once scraped it is passed through image classification, toxic text detection and news similarity check algorithm respectively. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To run this code, you will need to have an Instagram Account. This account shall be used for monitoring purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this algorithm, execute all the cells given below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Sakshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sakshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "from pandas import DataFrame as df\n",
    "nltk.download('stopwords')\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pickle\n",
    "import anvil\n",
    "import anvil.media\n",
    "import cv2\n",
    "from pytesseract import *\n",
    "#Paste your path to tesseract.exe below\n",
    "pytesseract.tesseract_cmd= r'C:\\Users\\Sakshi\\AppData\\Local\\Tesseract-OCR\\tesseract.exe'\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter your credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loginId=\"itspossible4630\"\n",
    "password=\"itspossible2020\"\n",
    "names=[\"itstesting4630\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialising Toxic Text Detection Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_toxic = pd.read_csv('Hindi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_processing(input_data):\n",
    "    filename_1 = 'TextModel_SVM.sav'\n",
    "    filename_2 = 'Vocabulary.sav'\n",
    "    clf = pickle.load(open(filename_1, 'rb'))\n",
    "    loaded_vec =  pickle.load(open(filename_2, \"rb\"))\n",
    "    loaded_vec = CountVectorizer(decode_error=\"replace\",vocabulary=loaded_vec)\n",
    "    text = []\n",
    "    text.append(input_data)\n",
    "    score = 0\n",
    "    keyword = re.sub('[^a-zA-Z]',' ',text[0])\n",
    "    for i in keyword.split(' '):\n",
    "        for j in hindi_toxic['Words']:\n",
    "            if j == i:\n",
    "                score = 1\n",
    "                break\n",
    "    if score == 1:\n",
    "        print('Score: ', score)\n",
    "        return('Not Okay')\n",
    "    else:\n",
    "        X = loaded_vec.transform(text)\n",
    "        score = clf.predict(X)\n",
    "        print('Score', score[0])\n",
    "        if score == 1:\n",
    "            return('Not Okay')\n",
    "        else:\n",
    "            return('Okay')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialising Image Classification Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_processing(path):\n",
    "    res = []\n",
    "    imagelen = []\n",
    "    filename = 'finalized_model.sav'\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "    #path = r'C:\\Users\\Sakshi\\FinalYearProject\\NSFW Test Dataset-20200515T145850Z-001\\giphy (2).gif'\n",
    "    #vidcap = cv2.VideoCapture(r'C:\\Users\\Sakshi\\FinalYearProject\\NSFW Test Dataset-20200515T145850Z-001\\download.jfif')\n",
    "    url = path\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    if img is not None:\n",
    "\n",
    "                #print('yes')\n",
    "                test_img = img.resize((32,32))\n",
    "                test_img = tf.keras.preprocessing.image.img_to_array(test_img)\n",
    "                test_img = np.expand_dims(test_img, axis = 0)\n",
    "                result = model.predict(test_img)\n",
    "                #print(result)\n",
    "                if result[0][4] == 1 or result[0][5] == 1:\n",
    "                    #print('okay')\n",
    "                    return ('Okay')\n",
    "                else:\n",
    "                    #print('not okay')\n",
    "                    return ('Not Okay')\n",
    "\n",
    "    else:\n",
    "\n",
    "            vidcap = cv2.VideoCapture(url)\n",
    "            success, image = vidcap.read()\n",
    "            #print(image.shape)\n",
    "            count = 0\n",
    "            while success:\n",
    "                success,image = vidcap.read()\n",
    "                if success:\n",
    "                    print('read a new frame:', success)\n",
    "                    count+=1\n",
    "                    images = cv2.resize(image, (32,32),3)\n",
    "                    #images  = images.reshape(32,32,3)\n",
    "                    #rint(image.shape)\n",
    "                    test_img = np.expand_dims(images, axis = 0)\n",
    "                    result = model.predict(test_img)\n",
    "                    res.append(result)\n",
    "                else:\n",
    "                       break \n",
    "            print('XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')\n",
    "            #print(len(res))\n",
    "            okay = 0\n",
    "            notokay = 0\n",
    "            for result in res:\n",
    "                #print(res)\n",
    "                if result[0][4] == 1 or result[0][5] == 1:\n",
    "                    okay+=1 \n",
    "                else:\n",
    "                    notokay+=1\n",
    "            #print('Okay Count: ',okay)\n",
    "            #print('Not Okay Count:',notokay)\n",
    "            if okay > notokay:\n",
    "              #  print('okay')\n",
    "                return ('Okay')\n",
    "            else:\n",
    "               # print('notokay')\n",
    "                return ('Not Okay')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extracting text from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagetext_processing(path):\n",
    "        url = path\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        try:\n",
    "            text=pytesseract.image_to_string(img)\n",
    "            print('Text', text)\n",
    "            score = comment_processing(text)\n",
    "            return (score)\n",
    "        except:\n",
    "            return('ohh okay')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Checking for Similar News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(keyword):\n",
    "    temp = []\n",
    "    keyword = re.sub('[^a-zA-Z]',' ',keyword)\n",
    "    ss=nltk.tokenize.sent_tokenize(keyword)\n",
    "    tokenized_sent=[nltk.word_tokenize(sent) for sent in ss]\n",
    "    pos_sentences=[nltk.pos_tag(sent) for sent in tokenized_sent]\n",
    "    for i in pos_sentences:\n",
    "        print(i)\n",
    "        for j in i:\n",
    "            print(j[1])\n",
    "            if j[1] == 'NN' or j[1] == 'NNP' or j[1] == 'NNPS':\n",
    "                temp.append(j[0])\n",
    "    return temp\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@anvil.server.callable\n",
    "\n",
    "def news_processing(sentence):\n",
    "    try:\n",
    "        sentence_1 = sentence\n",
    "        sentence = clean_text(sentence)\n",
    "        for word in sentence:\n",
    "            print(word)\n",
    "            keyword = '09-09-2020'\n",
    "            value = keyword + '.csv'\n",
    "            data = os.path.join(r'C:\\Data', keyword, 'data',value)\n",
    "            print(data)\n",
    "            data=pd.read_csv(data,  encoding='cp1252')\n",
    "            data_1= data[\"NEWS\"]\n",
    "            data_2 = data['NEWS URL']\n",
    "            super_1 = []\n",
    "            super_2 = []\n",
    "            super_3 = []\n",
    "            focus_sentence = sentence_1\n",
    "            focus_sentence = \" \".join(re.findall(\"[a-zA-Z]+\", focus_sentence)) \n",
    "            res = []\n",
    "            sent_list = []\n",
    "            urls = []\n",
    "            for row,url in zip(data_1,data_2):\n",
    "                sent=sent_tokenize(row)\n",
    "                for sentence in sent:\n",
    "                    sentence = \" \".join(re.findall(\"[a-zA-Z]+\", sentence)) \n",
    "                    corpus = [focus_sentence , sentence]\n",
    "                    vectorizer = TfidfVectorizer()\n",
    "                    trsfm=vectorizer.fit_transform(corpus)\n",
    "                    result = cosine_similarity(trsfm)[0][1]\n",
    "                    res.append(result.tolist())\n",
    "                    sent_list.append(sentence)\n",
    "                    urls.append(url)\n",
    "            print('XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')\n",
    "            final = res.index(max(res))\n",
    "            final_sentence = sent_list[final]\n",
    "            final_url = urls[final]\n",
    "            super_1.append(final)\n",
    "            super_2.append(final_sentence)\n",
    "            super_3.append(final_url)\n",
    "            print(final_sentence, max(res))\n",
    "        final = super_1.index(max(super_1))\n",
    "        final_sentence = super_2[final]\n",
    "        urls = super_3[final]\n",
    "\n",
    "\n",
    "        return ('Input News: ',sentence_1, 'Similar News', final_sentence,'Similarity Score: ', max(res),urls)\n",
    "    except:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Scraping Direct Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inorder to start scraping instagram messages, you need to follow the following steps:\n",
    "1. Use any other instagram account and not the one you have used for monitoring, such that both the accounts\n",
    "   follow each other\n",
    "2. From that account, send a message to the account used for monitoring. \n",
    "        1. If the message sent is a text, call the last_text() function as shown below.\n",
    "        2. If the message is an image, call the last_image() function as shown below.\n",
    "3. Execute the code given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_user():\n",
    "    username = driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[1]/div/label/input')\n",
    "    username.send_keys(loginId)\n",
    "    passw=driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[2]/div/label/input')\n",
    "    passw.send_keys(password)\n",
    "    login=driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[3]/button').click()\n",
    "\n",
    "    print(\"Welcome To Instagram\")\n",
    "    \n",
    "def check_msg():\n",
    "     for name in names:\n",
    "        search_box = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]').click()\n",
    "        type=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input')\n",
    "        type.send_keys(name)\n",
    "        type.send_keys(Keys.ENTER)\n",
    "        type.send_keys(Keys.ENTER)\n",
    "        print(\"Logged In....\")\n",
    "\n",
    "def user_found():\n",
    "    user = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div/div[2]/div/div/a').click()\n",
    "    #check_user=driver.find_element_by_id('//span[@dir=\"uyeeR\"]').text\n",
    "    #print(check_user)\n",
    "    time.sleep(8)\n",
    "    user_text=driver.find_element_by_class_name('_8A5w5').click()\n",
    "    time.sleep(5)\n",
    "    #msg=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/div/div[2]/div/div/div[2]/div[2]/div/div[2]/div/div/div[2]/textarea')\n",
    "    #msg.send_keys(message)\n",
    "    #msg.send_keys(Keys.ENTER)\n",
    "    print(\"User Found!!\")\n",
    "\n",
    "def last_image():\n",
    "    for i in range(1,43):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    #body = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/div/div[2]/div/div/div[2]/div[2]/div/div[1]/div/div/div[4]/div[2]/div/div/div/div/div/div/div/img')\n",
    "    body = driver.find_elements_by_class_name('QzzMF ')\n",
    "    body = body[-1]\n",
    "    body.click()\n",
    "    time.sleep(5)\n",
    "    imgsrc = driver.find_element_by_xpath('/html/body/div[6]/div/div[2]/div/div')\n",
    "    imgsrc = driver.find_element_by_xpath('/html/body/div[6]/div/div[2]/div/div/img')\n",
    "    src = imgsrc.get_attribute(\"src\")\n",
    "    time.sleep(3)\n",
    "    close = driver.find_element_by_xpath('/html/body/div[6]/div/div[1]/button/div').click()\n",
    "    print('Last Image Source: ',src)\n",
    "    score_1 = imagetext_processing(src)\n",
    "    score_2 = image_processing(src)\n",
    "    print('Score 1: ', score_1)\n",
    "    print('Score 2: ', score_2)\n",
    "\n",
    "    if score_1 == 'Not Okay' or score_2 == 'Not Okay':\n",
    "                print('Result: Toxic')\n",
    "                message = 'Sent by bot: Your following message ' + src + ' might have a negative social impact. Hereby, You are requested to delete it.'\n",
    "                msg=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/div/div[2]/div/div/div[2]/div[2]/div/div[2]/div/div/div[2]/textarea')\n",
    "                msg.send_keys(message)\n",
    "                msg.send_keys(Keys.ENTER)\n",
    "                print('User Notified')\n",
    "\n",
    "    else:\n",
    "        print('Result: Not Toxic')\n",
    "            \n",
    "    \n",
    "def last_text():\n",
    "        body=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/div/div[2]/div/div/div[2]/div[2]/div/div[1]').text\n",
    "        time.sleep(5)\n",
    "        check_data = body.split('\\n')\n",
    "        check_data = check_data[-1]\n",
    "        score = comment_processing(check_data)\n",
    "        print('Last Text: ', check_data)\n",
    "        if score == 'Not Okay':\n",
    "                    print('Result: Toxic')\n",
    "                    message = 'Sent by bot: Your following message ' + check_data  + ' might have a negative social impact. Hereby, You are requested to delete it.'\n",
    "                    msg=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/div/div[2]/div/div/div[2]/div[2]/div/div[2]/div/div/div[2]/textarea')\n",
    "                    msg.send_keys(message)\n",
    "                    msg.send_keys(Keys.ENTER)\n",
    "                    print('User Notified')\n",
    "\n",
    "        else:\n",
    "            print('Result: Not Toxic')\n",
    "            \n",
    "def loop_forever_text():\n",
    "    count = 0\n",
    "    while count!=1:\n",
    "        try:\n",
    "            print(count)\n",
    "            time.sleep(10)\n",
    "            last_text()\n",
    "            count+=1\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "def loop_forever_image():\n",
    "    count = 0\n",
    "    while count!=1:\n",
    "        try:\n",
    "            print(count)\n",
    "            time.sleep(10)\n",
    "            last_image()\n",
    "            count+=1\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome To Instagram\n",
      "Logged In....\n",
      "User Found!!\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(executable_path='chromedriver.exe')\n",
    "driver.get(\"https://www.instagram.com/\")\n",
    "#input(\"Enter something: \")\n",
    "time.sleep(15)\n",
    "login_user()\n",
    "time.sleep(4)\n",
    "check_msg()\n",
    "time.sleep(5)\n",
    "user_found()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  1\n",
      "Last Text:  You bastard, why don't you just die\n",
      "Result: Toxic\n",
      "User Notified\n"
     ]
    }
   ],
   "source": [
    "last_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Image Source:  https://instagram.fbom3-1.fna.fbcdn.net/v/t51.2885-15/e35/243716933_678455956877458_5765977947655476332_n.jpg?_nc_ht=instagram.fbom3-1.fna.fbcdn.net&_nc_cat=110&_nc_ohc=HCr0NIHwbxcAX8KVOFk&edm=ABJHkxYAAAAA&ccb=7-4&oh=2c24d228f9da6356063444368cd5221b&oe=615C3964&_nc_sid=fa978c&ig_cache_key=MjY3MzUxMDM1NDE3ODQ3NjMxOQ%3D%3D.2-ccb7-4\n",
      "Text SOLIFUGAE (SCORPION SPIDER)\n",
      "\n",
      " \n",
      "\n",
      "MOTHER OF GOD\n",
      "\n",
      "Â») JUSTDWL.NET\n",
      "Score 1\n",
      "Score 1:  Not Okay\n",
      "Score 2:  Not Okay\n",
      "Result: Toxic\n",
      "User Notified\n"
     ]
    }
   ],
   "source": [
    "last_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Scraping Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inorder to start scraping the instagram posts, you need to follow the following steps:\n",
    "1. Use any other instagram account and not the one you have used for monitoring, such that both the accounts\n",
    "    follow each other \n",
    "2. From that account, post 3 things\n",
    "        1. an image as a tweet using the hashtag #itstestingimage_3\n",
    "        2. an image containing text using the hahstag #itstestingimage_3\n",
    "        3. an image containing news (formulate a news from the COVID.csv given for convinience) using the hashtag                          #itstestingimage_3   \n",
    "3. Once you have posted, run the code given below, you shall see a message from the account used for monitoring, if any of        the text or image posted is inappropriate. For the news, you shall see a comment with the URL of the most similar news          found from the Bot account(The account used for monitoring)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_user():\n",
    "    username = driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[1]/div/label/input')\n",
    "    username.send_keys(loginId)\n",
    "    passw=driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[2]/div/label/input')\n",
    "    passw.send_keys(password)\n",
    "    login=driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[3]/button').click()\n",
    "\n",
    "    print(\"Welcome To Instagram\")\n",
    "    \n",
    "def check_msg():\n",
    "        search_box = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div/div').click()\n",
    "        type=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input')\n",
    "        name = '#itstestingimage_3'\n",
    "        type.send_keys(name)\n",
    "        time.sleep(3)\n",
    "        type.send_keys(Keys.ENTER)\n",
    "        time.sleep(3)\n",
    "        type.send_keys(Keys.ENTER)\n",
    "        print(\"Logged In....\")\n",
    "        \n",
    "\n",
    "def user_found():\n",
    "    user = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div/div[2]/div/div/a').click()\n",
    "    #check_user=driver.find_element_by_id('//span[@dir=\"uyeeR\"]').text\n",
    "    #print(check_user)\n",
    "    time.sleep(5)\n",
    "    user_text=driver.find_element_by_class_name('_8A5w5').click() \n",
    "    time.sleep(5)\n",
    "    #msg=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/div/div[2]/div/div/div[2]/div[2]/div/div[2]/div/div/div[2]/textarea')\n",
    "    #msg.send_keys(message)\n",
    "    #msg.send_keys(Keys.ENTER)\n",
    "    print(\"User Found!!\")\n",
    "\n",
    "def last_text():\n",
    "    for i in range(1,43):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        body = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/div/div[2]/div/div/div[2]/div[2]/div/div[1]/div/div/div[4]/div[2]/div/div/div/div/div/div/div/img')\n",
    "        src = body.get_attribute(\"src\")\n",
    "        print('Last Image Source: ',src)\n",
    "        score_1 = imagetext_processing(src)\n",
    "        score_2 = image_processing(src)\n",
    "\n",
    "\n",
    "        if score_1 == 'Not Okay' or score_2 == 'Not Okay':\n",
    "                    print('Result: Toxic')\n",
    "                    message = 'Sent by bot: Your following message ' + src + ' might have a negative social impact. Hereby, You are requested to delete it.'\n",
    "                    msg=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/div/div[2]/div/div/div[2]/div[2]/div/div[2]/div/div/div[2]/textarea')\n",
    "                    msg.send_keys(message)\n",
    "                    msg.send_keys(Keys.ENTER)\n",
    "                    print('User Notified')\n",
    "\n",
    "        else:\n",
    "            print('Result: Not Toxic')\n",
    "            \n",
    "    \n",
    "    except:\n",
    "        body=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/div/div[2]/div/div/div[2]/div[2]/div/div[1]').text\n",
    "        time.sleep(5)\n",
    "        check_data = body.split('\\n')\n",
    "        check_data = check_data[-1]\n",
    "        score = comment_processing(check_data)\n",
    "        print('Last Text: ', check_data)\n",
    "        if score == 1:\n",
    "                    print('Result: Toxic')\n",
    "                    message = 'Sent by bot: Your following message ' + check_data  + ' might have a negative social impact. Hereby, You are requested to delete it.'\n",
    "                    msg=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/div/div[2]/div/div/div[2]/div[2]/div/div[2]/div/div/div[2]/textarea')\n",
    "                    msg.send_keys(message)\n",
    "                    msg.send_keys(Keys.ENTER)\n",
    "                    print('User Notified')\n",
    "\n",
    "        else:\n",
    "            print('Result: Not Toxic')\n",
    "            \n",
    "def last_feed():\n",
    "    feed = driver.find_element_by_class_name('KL4Bh')\n",
    "    feed = driver.find_element_by_class_name('FFVAD')\n",
    "    src = feed.get_attribute('src')\n",
    "    time.sleep(3)\n",
    "    feed = driver.find_element_by_class_name('_9AhH0').click()\n",
    "    time.sleep(3)\n",
    "    #username = driver.find_element_by_xpath('/html/body/div[4]/div[2]/div/article/div/div[3]/div[1]/ul/div/li/div/div/div[2]/h2/div/span/a')\n",
    "    #print(username)\n",
    "    caption =  driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[2]/div[1]/ul/div/li/div/div/div[2]').text\n",
    "    print(caption)\n",
    "    score_1 = imagetext_processing(src)\n",
    "    print('Score 1: ', score_1)\n",
    "    score_2 = image_processing(src)\n",
    "    print('Score 2', score_2)\n",
    "    score_3 = comment_processing(caption)\n",
    "    print('Score 3', score_3)\n",
    "    \n",
    "\n",
    "    if score_1 == 'Not Okay' or score_2 == 'Not Okay' or score_3 == 'Not Okay':\n",
    "        print('Result: Toxic')\n",
    "        user = driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[1]/div/header/div[2]/div[1]/div[1]/span/a').click()\n",
    "        time.sleep(8)\n",
    "        user=driver.find_element_by_class_name('_8A5w5').click() \n",
    "        time.sleep(5)\n",
    "        message = 'Sent by bot: Your following message ' + src + ' might have a negative social impact. Hereby, You are requested to delete it.'\n",
    "        time.sleep(5)\n",
    "        msg=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/div/div[2]/div/div/div[2]/div[2]/div/div[2]/div/div/div[2]/textarea')\n",
    "        msg.send_keys(message)\n",
    "        msg.send_keys(Keys.ENTER)\n",
    "        print('User Notified')\n",
    "\n",
    "    else:\n",
    "            print('Result: Not Toxic')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged In....\n",
      "itstesting4630\n",
      "#itstestingimage_3\n",
      "58w\n",
      "Text bollywoodoriginals * Follow\n",
      "\n",
      "rhea_chakraborty @\n",
      "\n",
      "mannu_raaut\n",
      "\n",
      " \n",
      "\n",
      "I make sure u will b raped n\n",
      "murdered ! U bitch commit suicide\n",
      "otherwise i will send people to kill u\n",
      "\n",
      "(Gy sooner or later !\n",
      "Score:  1\n",
      "Score 1:  Not Okay\n",
      "Score 2 Okay\n",
      "Score 0\n",
      "Score 3 Okay\n",
      "Result: Toxic\n",
      "User Notified\n"
     ]
    }
   ],
   "source": [
    "check_msg()\n",
    "time.sleep(5)\n",
    "#user_found()\n",
    "time.sleep(2)\n",
    "#last_text()\n",
    "result = last_feed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_user():\n",
    "    username = driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[1]/div/label/input')\n",
    "    username.send_keys(loginId)\n",
    "    passw=driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[2]/div/label/input')\n",
    "    passw.send_keys(password)\n",
    "    login=driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[3]/button').click()\n",
    "\n",
    "    print(\"Welcome To Instagram\")\n",
    "    \n",
    "def check_msg():\n",
    "        search_box = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div/div').click()\n",
    "        type=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input')\n",
    "        name = '#itstestingnews_2'\n",
    "        type.send_keys(name)\n",
    "        time.sleep(3)\n",
    "        type.send_keys(Keys.ENTER)\n",
    "        time.sleep(3)\n",
    "        type.send_keys(Keys.ENTER)\n",
    "        print(\"Logged In....\")\n",
    "        \n",
    "\n",
    "def user_found():\n",
    "    user = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div/div[2]/div/div/a').click()\n",
    "    #check_user=driver.find_element_by_id('//span[@dir=\"uyeeR\"]').text\n",
    "    #print(check_user)\n",
    "    time.sleep(5)\n",
    "    user_text=driver.find_element_by_class_name('_8A5w5').click() \n",
    "    time.sleep(5)\n",
    "    #msg=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/div/div[2]/div/div/div[2]/div[2]/div/div[2]/div/div/div[2]/textarea')\n",
    "    #msg.send_keys(message)\n",
    "    #msg.send_keys(Keys.ENTER)\n",
    "    print(\"User Found!!\")\n",
    "\n",
    "def last_text():\n",
    "    for i in range(1,43):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        body = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/div/div[2]/div/div/div[2]/div[2]/div/div[1]/div/div/div[4]/div[2]/div/div/div/div/div/div/div/img')\n",
    "        src = body.get_attribute(\"src\")\n",
    "        print('Last Image Source: ',src)\n",
    "        score_1 = imagetext_processing_news(src)\n",
    "        score_2 = image_processing(src)\n",
    "\n",
    "\n",
    "        if score_1 == 'Not Okay' or score_2 == 'Not Okay':\n",
    "                    print('Result: Toxic')\n",
    "                    message = 'Sent by bot: Your following message ' + src + ' might have a negative social impact. Hereby, You are requested to delete it.'\n",
    "                    msg=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/div/div[2]/div/div/div[2]/div[2]/div/div[2]/div/div/div[2]/textarea')\n",
    "                    msg.send_keys(message)\n",
    "                    msg.send_keys(Keys.ENTER)\n",
    "                    print('User Notified')\n",
    "\n",
    "        else:\n",
    "            print('Result: Not Toxic')\n",
    "            \n",
    "    \n",
    "    except:\n",
    "        body=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/div/div[2]/div/div/div[2]/div[2]/div/div[1]').text\n",
    "        time.sleep(5)\n",
    "        check_data = body.split('\\n')\n",
    "        check_data = check_data[-1]\n",
    "        score = comment_processing(check_data)\n",
    "        print('Last Text: ', check_data)\n",
    "        if score == 1:\n",
    "                    print('Result: Toxic')\n",
    "                    message = 'Sent by bot: Your following message ' + check_data  + ' might have a negative social impact. Hereby, You are requested to delete it.'\n",
    "                    msg=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/div/div[2]/div/div/div[2]/div[2]/div/div[2]/div/div/div[2]/textarea')\n",
    "                    msg.send_keys(message)\n",
    "                    msg.send_keys(Keys.ENTER)\n",
    "                    print('User Notified')\n",
    "\n",
    "        else:\n",
    "            print('Result: Not Toxic')\n",
    "            \n",
    "def last_feed():\n",
    "    feed = driver.find_element_by_class_name('KL4Bh')\n",
    "    feed = driver.find_element_by_class_name('FFVAD')\n",
    "    src = feed.get_attribute('src')\n",
    "    time.sleep(3)\n",
    "    feed = driver.find_element_by_class_name('_9AhH0').click()\n",
    "    time.sleep(3)\n",
    "    #username = driver.find_element_by_xpath('/html/body/div[4]/div[2]/div/article/div/div[3]/div[1]/ul/div/li/div/div/div[2]/h2/div/span/a')\n",
    "    #print(username)\n",
    "    caption =  driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[2]/div[1]/ul/div/li/div/div/div[2]').text\n",
    "    print(caption)\n",
    "    score_1 = imagetext_processing_news(src)\n",
    "    print('Score 1: ', score_1)\n",
    "    score_2 = image_processing(src)\n",
    "    print('Score 2', score_2)\n",
    "    \n",
    "    \n",
    "\n",
    "    if score_2 == 'Not Okay':\n",
    "        print('Result: Toxic')\n",
    "        user = driver.find_element_by_xpath('/html/body/div[6]/div[2]/div/article/div/div[2]/div/div[1]/div/header/div[2]/div[1]/div[1]/span/a').click()\n",
    "        time.sleep(8)\n",
    "        user=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/header/section/div[1]').click()\n",
    "        time.sleep(5)\n",
    "        message = 'Sent by bot: Your following message ' + src + ' might have a negative social impact. Hereby, You are requested to delete it.'\n",
    "        time.sleep(5)\n",
    "        msg=driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/div/div[2]/div/div/div[2]/div[2]/div/div[2]/div/div/div[2]/textarea')\n",
    "        msg.send_keys(message)\n",
    "        msg.send_keys(Keys.ENTER)\n",
    "        print('User Notified')\n",
    "        \n",
    "    elif score_1[-2] < 0.5 :\n",
    "        print('Result: Toxic')\n",
    "        comment = driver.find_element_by_class_name('Ypffh')\n",
    "        message = 'Sent by bot: ' + score_1[-1]\n",
    "        comment.send_keys(message)\n",
    "        #comment.send_keys(Keys.ENTER)\n",
    "\n",
    "            \n",
    "        \n",
    "\n",
    "    else:\n",
    "            print('Result: Not Toxic')\n",
    "            \n",
    "def imagetext_processing_news(path):\n",
    "        url = path\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        try:\n",
    "            text=pytesseract.image_to_string(img)\n",
    "            print('Text', text)\n",
    "            score = news_processing(text)\n",
    "            return (score)\n",
    "        except:\n",
    "            return('ohh okay')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged In....\n",
      "itstesting4630\n",
      "#itstestingnews_2\n",
      "55w\n",
      "Text childeren sent to Delhi\n",
      "for working in factories\n",
      "\n",
      "have been rescued\n",
      "[('childeren', 'NN'), ('sent', 'VBD'), ('to', 'TO'), ('Delhi', 'NNP'), ('for', 'IN'), ('working', 'VBG'), ('in', 'IN'), ('factories', 'NNS'), ('have', 'VBP'), ('been', 'VBN'), ('rescued', 'VBN')]\n",
      "NN\n",
      "VBD\n",
      "TO\n",
      "NNP\n",
      "IN\n",
      "VBG\n",
      "IN\n",
      "NNS\n",
      "VBP\n",
      "VBN\n",
      "VBN\n",
      "childeren\n",
      "C:\\Data\\09-09-2020\\data\\09-09-2020.csv\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "According to the police the children were to be sent to work in factories in Haryana and Punjab from Delhi 0.29495047131618174\n",
      "Delhi\n",
      "C:\\Data\\09-09-2020\\data\\09-09-2020.csv\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "According to the police the children were to be sent to work in factories in Haryana and Punjab from Delhi 0.29495047131618174\n",
      "Score 1:  ('Input News: ', 'childeren sent to Delhi\\nfor working in factories\\n\\nhave been rescued', 'Similar News', 'According to the police the children were to be sent to work in factories in Haryana and Punjab from Delhi', 'Similarity Score: ', 0.29495047131618174, 'http://zeenews.india.com/india/delhi-polices-railway-unit-rescues-14-minors-brought-from-bihar-to-work-in-factories-2308624.html')\n",
      "Score 2 Okay\n",
      "Result: Toxic\n"
     ]
    }
   ],
   "source": [
    "check_msg()\n",
    "time.sleep(5)\n",
    "#user_found()\n",
    "time.sleep(2)\n",
    "#last_text()\n",
    "last_feed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SakshiEnv] *",
   "language": "python",
   "name": "conda-env-SakshiEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
